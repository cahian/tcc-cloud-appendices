# ApÃªndices do TCC - EficiÃªncia e Escalabilidade com Cloud Computing

Scripts completos do protÃ³tipo desenvolvido para processamento Big Data em nuvem AWS.

**Autor:** Cahian Freire
**InstituiÃ§Ã£o:** Universidade Paulista (UNIP)
**Ano:** 2025

---

## ğŸ“‹ Ãndice de ApÃªndices

### [ApÃªndice A - Scripts Python/PySpark](A_spark_scripts/)
Scripts de processamento distribuÃ­do de dados com Apache Spark 3.2.0.

**Arquivos:**
- [`ingest_data.py`](A_spark_scripts/ingest_data.py) - IngestÃ£o de dados do S3 com validaÃ§Ã£o
- [`process_data.py`](A_spark_scripts/process_data.py) - Processamento ETL e agregaÃ§Ãµes
- [`spark_optimizer.py`](A_spark_scripts/spark_optimizer.py) - ConfiguraÃ§Ãµes otimizadas

**Tecnologias:** PySpark 3.2.0, boto3, PyArrow

---

### [ApÃªndice B - ConfiguraÃ§Ãµes Terraform](B_terraform/)
Infraestrutura como CÃ³digo para provisionamento AWS.

**Arquivos:**
- [`main.tf`](B_terraform/main.tf) - Provider AWS
- [`emr_cluster.tf`](B_terraform/emr_cluster.tf) - Cluster EMR com auto-scaling
- [`s3.tf`](B_terraform/s3.tf) - Buckets S3 (Data Lake + Logs)
- [`iam.tf`](B_terraform/iam.tf) - Roles e policies
- [`network.tf`](B_terraform/network.tf) - VPC e subnets
- [`variables.tf`](B_terraform/variables.tf) - VariÃ¡veis configurÃ¡veis
- [`outputs.tf`](B_terraform/outputs.tf) - Outputs do cluster

**Recursos:** EMR cluster, S3, VPC, IAM, Auto-scaling (2-16 nodes)

---

### [ApÃªndice C - DAGs Apache Airflow](C_airflow_dags/)
OrquestraÃ§Ã£o automatizada de pipelines Big Data.

**DAGs:**
- [`daily_etl_dag.py`](C_airflow_dags/dags/daily_etl_dag.py) - Pipeline ETL diÃ¡rio
- [`scalability_test_dag.py`](C_airflow_dags/dags/scalability_test_dag.py) - Testes de escalabilidade
- [`monitoring_dag.py`](C_airflow_dags/dags/monitoring_dag.py) - Monitoramento contÃ­nuo

**Schedule:**
- ETL: DiÃ¡rio (@daily)
- Benchmarks: Semanal (@weekly)
- Monitoring: A cada 6 horas

---

### [ApÃªndice D - Scripts de Monitoramento](D_monitoring_scripts/)
Coleta de mÃ©tricas, anÃ¡lise de custos e eficiÃªncia energÃ©tica.

**Scripts:**
- [`cloudwatch_metrics.py`](D_monitoring_scripts/cloudwatch_metrics.py) - MÃ©tricas AWS CloudWatch
- [`benchmark_suite.py`](D_monitoring_scripts/benchmark_suite.py) - Suite de benchmarks
- [`cost_tracker.py`](D_monitoring_scripts/cost_tracker.py) - AnÃ¡lise de custos
- [`energy_monitor.py`](D_monitoring_scripts/energy_monitor.py) - EficiÃªncia energÃ©tica
- [`monitor_job.py`](D_monitoring_scripts/monitor_job.py) - Monitoramento contÃ­nuo de clusters EMR (suporte a `--dry-run`)

**Funcionalidades:**
- Performance: Throughput, latÃªncia, escalabilidade
- Custos: Spot vs On-Demand, custo/GB, estimativas mensais
- Energia: kWh/TB, pegada de carbono, comparaÃ§Ã£o regional
- Monitoramento: status dos clusters, mÃ©tricas CloudWatch, alertas bÃ¡sicos

---

### [ApÃªndice E - Dados Experimentais e ConfiguraÃ§Ãµes](E_experiments/)
Resultados completos dos experimentos e configuraÃ§Ãµes recomendadas.

**Arquivos:**
- [`experiment_results.csv`](E_experiments/experiment_results.csv) - Tabelas completas das execuÃ§Ãµes
- [`cluster_configs.yaml`](E_experiments/cluster_configs.yaml) - Ajustes finais de hardware/Spark
- [`analyze_results.py`](E_experiments/analyze_results.py) - Script para gerar estatÃ­sticas
- [`README.md`](E_experiments/README.md) - Guia de uso

---

## ğŸš€ Quick Start

### Requisitos

```bash
# Python 3.9+
pip install -r A_spark_scripts/requirements.txt
pip install -r C_airflow_dags/requirements.txt
pip install -r D_monitoring_scripts/requirements.txt

# Terraform 1.0+ (para ApÃªndice B)
# AWS CLI configurado
```

### Testes RÃ¡pidos

```bash
# Testar otimizador Spark
python3 A_spark_scripts/spark_optimizer.py

# Executar benchmarks
python3 D_monitoring_scripts/benchmark_suite.py

# AnÃ¡lise de custos
python3 D_monitoring_scripts/cost_tracker.py

# AnÃ¡lise energÃ©tica
python3 D_monitoring_scripts/energy_monitor.py

# Monitoramento (modo simulado)
python3 D_monitoring_scripts/monitor_job.py --cluster-id demo --dry-run

# EstatÃ­sticas dos experimentos
python3 E_experiments/analyze_results.py
```

### ValidaÃ§Ã£o Terraform

```bash
cd B_terraform
terraform init
terraform validate
terraform plan
```

---

## ğŸ“Š Resultados Principais (do TCC)

### Performance
- **Apache Spark:** 35% mais rÃ¡pido que Hadoop (speedup 1.53x)
- **Google BigQuery:** 108% mais rÃ¡pido que Hadoop (speedup 2.08x)
- **Throughput mÃ¡ximo:** 2.5 TB/hora (cluster 16 nodes)

### Custos
- **Economia com Spot:** 60% vs On-Demand
- **ReduÃ§Ã£o total:** 42% com auto-scaling + spot
- **Custo mÃ©dio:** $0.10/GB processado

### Escalabilidade
- **Auto-scaling:** 2-16 instÃ¢ncias
- **EficiÃªncia:** ~80% linear atÃ© 16 nodes
- **Threshold:** Scale-up em 70% CPU, Scale-down em 30%

### Sustentabilidade
- **Melhor regiÃ£o:** sa-east-1 (0.098 kg COâ‚‚/kWh - hidrelÃ©trica)
- **Pior regiÃ£o:** us-east-1 (0.385 kg COâ‚‚/kWh)
- **ReduÃ§Ã£o potencial:** 74.5% mudando de regiÃ£o

---

## ğŸ“ Estrutura Completa

```
appendices/
â”œâ”€â”€ A_spark_scripts/
â”‚   â”œâ”€â”€ ingest_data.py (91 linhas)
â”‚   â”œâ”€â”€ process_data.py (81 linhas)
â”‚   â”œâ”€â”€ spark_optimizer.py (76 linhas)
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ B_terraform/
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ variables.tf (46 linhas)
â”‚   â”œâ”€â”€ s3.tf (48 linhas)
â”‚   â”œâ”€â”€ iam.tf (92 linhas)
â”‚   â”œâ”€â”€ emr_cluster.tf (124 linhas)
â”‚   â”œâ”€â”€ network.tf (54 linhas)
â”‚   â”œâ”€â”€ outputs.tf (27 linhas)
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ C_airflow_dags/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ daily_etl_dag.py (142 linhas)
â”‚   â”‚   â”œâ”€â”€ scalability_test_dag.py (90 linhas)
â”‚   â”‚   â””â”€â”€ monitoring_dag.py (143 linhas)
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ D_monitoring_scripts/
â”‚   â”œâ”€â”€ cloudwatch_metrics.py (115 linhas)
â”‚   â”œâ”€â”€ benchmark_suite.py (143 linhas)
â”‚   â”œâ”€â”€ cost_tracker.py (243 linhas)
â”‚   â”œâ”€â”€ energy_monitor.py (257 linhas)
â”‚   â”œâ”€â”€ monitor_job.py (170 linhas)
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ E_experiments/
â”‚   â”œâ”€â”€ experiment_results.csv (10 linhas)
â”‚   â”œâ”€â”€ cluster_configs.yaml (36 linhas)
â”‚   â”œâ”€â”€ analyze_results.py (90 linhas)
â”‚   â””â”€â”€ README.md
â””â”€â”€ README.md (este arquivo)

Total: ~1.9k linhas de cÃ³digo/dados
```

---

## âœ… ValidaÃ§Ãµes Realizadas

- âœ… **Sintaxe Python:** Todos os scripts compilam sem erros
- âœ… **Testes funcionais:** Benchmark, custos e energia executados com sucesso
- âœ… **Terraform:** Sintaxe validada (fmt + validate)
- âœ… **Airflow DAGs:** Sintaxe validada
- âœ… **DocumentaÃ§Ã£o:** READMEs completos em cada apÃªndice

---

## ğŸ“– Como Usar no TCC

Cada apÃªndice foi projetado para ser auto-contido e pode ser referenciado diretamente:

**Exemplo de citaÃ§Ã£o:**
> "O cÃ³digo completo do processamento Spark estÃ¡ disponÃ­vel no ApÃªndice A,
> incluindo otimizaÃ§Ãµes de configuraÃ§Ã£o conforme descrito no arquivo
> `spark_optimizer.py` (linhas 15-35)."

---

## ğŸ”— ReferÃªncias TÃ©cnicas

- **Apache Spark:** 3.2.0
- **Hadoop:** 3.3.1
- **EMR Release:** emr-6.9.0
- **Terraform:** >= 1.0
- **Airflow:** 2.7.0
- **Python:** 3.9+
- **AWS Provider:** ~> 4.0

---

## ğŸ“ LicenÃ§a

Este cÃ³digo foi desenvolvido para fins acadÃªmicos como parte do TCC de
Bacharelado em CiÃªncia da ComputaÃ§Ã£o da UNIP (2025).

---

**Data de criaÃ§Ã£o:** Novembro 2025
**Ãšltima atualizaÃ§Ã£o:** {{ data_atual }}
